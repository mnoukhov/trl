model_name: "EleutherAI/pythia-410m-deduped"
output_model_name: "sophiex/pythia-410m-sft_hh_rlhf"
dataset_name: "sophiex/hh-rlhf"
dataset_text_field: null
report_to: "wandb"
learning_rate: 1e-5
lr_scheduler_type: cosine
warmup_steps: 100
weight_decay: 0.05
load_in_8bit: False
fp16: True
bf16: False
gradient_checkpointing: False
gradient_accumulation_steps: 4
per_device_train_batch_size: 4
per_device_eval_batch_size: 8
num_train_epochs: 3
max_seq_length: 1024
use_peft: True
lora_r: 8
lora_alpha: 32
