## model and dataset
model_name: mnoukhov/EleutherAI_pythia-2.8b-deduped__sft__tldr_55513 
# hub_model_id: "mnoukhov/pythia-2.8b-dpo_hh_rlhf"
dataset_name: mnoukhov/summarize_from_feedback_tldr3_unlabelled_vllm_dpo_costa_2.8b_bf16.yml_6e799_new
eval_dataset_name: vwxyzjn/summarize_from_feedback_oai_preprocessing_1706381144
dataset_eval_split: validation
report_to: "wandb"
## dpo
learning_rate: 1e-5
lr_scheduler_type: cosine
fp16: False
bf16: True
gradient_accumulation_steps: 8
per_device_train_batch_size: 8
per_device_eval_batch_size: 4
num_train_epochs: 1
max_length: 640
max_prompt_length: 512 
max_target_length: 128
beta: 0.05
## peft
use_peft: True
lora_r: 16
lora_alpha: 32
gradient_checkpointing: False
evaluation_strategy: "steps"
eval_steps: 0.2
logging_steps: 100
ddp_find_unused_parameters: False
